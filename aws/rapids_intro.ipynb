{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e8b9f92",
   "metadata": {},
   "source": [
    "# RAPIDS on AWS\n",
    "\n",
    "### Augment SageMaker with a RAPIDS Conda Kernel\n",
    "This section describes the process required to augment a SageMaker notebook instance with a RAPIDS conda environment.\n",
    "\n",
    "The RAPIDS Ops team builds and publishes the latest RAPIDS release as a packed conda tarball.\n",
    "\n",
    "e.g.: https://rapidsai-data.s3.us-east-2.amazonaws.com/conda-pack/rapidsai/rapids21.06_cuda11.0_py3.8.tar.gz\n",
    "\n",
    "We will use this packed conda environment to augment the set of Jupyter ipython kernels available in our SageMaker notebook instance.\n",
    "\n",
    "The key steps of this are as follows:\n",
    "\n",
    "1. During SageMaker Notebook Instance Startup\n",
    "- Select a RAPIDS compatible GPU (NVIDIA Pascal or greater with compute capability 6.0+) as the SageMaker Notebook instance type (e.g., ml.p3.2xlarge)\n",
    "- Attach the lifecycle configuration (via the 'Additional Options' dropdown) provided in this directory (also pasted in the Appendix of this notebook)\n",
    "2. Launch the instance\n",
    "3. Once Jupyter is accessible select the 'rapids-XX' kernel when working with a new notebook.\n",
    "\n",
    "### cuDF and cuML Examples\n",
    "\n",
    "Below are basic examples to get started with RAPIDS on AWS, where all processing takes place on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a5e46",
   "metadata": {},
   "source": [
    "### cuDF Example\n",
    "\n",
    "Load a dataset into GPU memory (cuDF DataFrame) and perform a basic calculation.\n",
    "\n",
    "Everything from CSV parsing to calculating tip percentage and computing a grouped average is done on the GPU.\n",
    "\n",
    "For information about cuDF, refer to the [cuDF documentation](https://docs.rapids.ai/api/cudf/stable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295b0535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size\n",
      "6    15.622920\n",
      "1    21.729202\n",
      "4    14.594901\n",
      "3    15.215685\n",
      "2    16.571919\n",
      "5    14.149549\n",
      "Name: tip_percentage, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import io, requests\n",
    "\n",
    "# Download CSV file from GitHub\n",
    "url=\"https://github.com/plotly/datasets/raw/master/tips.csv\"\n",
    "content = requests.get(url).content.decode('utf-8')\n",
    "\n",
    "# Read CSV from memory\n",
    "tips_df = cudf.read_csv(io.StringIO(content))\n",
    "tips_df['tip_percentage'] = tips_df['tip']/tips_df['total_bill']*100\n",
    "\n",
    "# Display average tip by dining party size\n",
    "print(tips_df.groupby('size').tip_percentage.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e85f7f",
   "metadata": {},
   "source": [
    "### cuML Example\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "Linear Regression is a simple machine learning model where the response y is modelled by a linear combination of the predictors in X.\n",
    "\n",
    "The model can take array-like objects, either in host as NumPy arrays or in device (as Numba or cuda_array_interface-compliant), as well as cuDF DataFrames as the input.\n",
    "\n",
    "NOTE: This notebook is not expected to run on a GPU with under 16GB of RAM with its current value for `n_smaples`. Please change `n_samples` from `2**20` to `2**19`.\n",
    "\n",
    "For information about cuML's linear regression API: https://docs.rapids.ai/api/cuml/stable/api.html#cuml.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b0a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import make_regression, train_test_split\n",
    "from cuml.linear_model import LinearRegression as cuLinearRegression\n",
    "from cuml.metrics.regression import r2_score\n",
    "from sklearn.linear_model import LinearRegression as skLinearRegression\n",
    "\n",
    "# Define parameters\n",
    "n_samples = 2**19 #If you are running on a GPU with less than 16GB RAM, please change to 2**19 or you could run out of memory\n",
    "n_features = 399\n",
    "\n",
    "random_state = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae31a745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 687 ms, total: 2.29 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate data\n",
    "X, y = make_regression(n_samples=n_samples, n_features=n_features, random_state=random_state)\n",
    "\n",
    "X = cudf.DataFrame(X)\n",
    "y = cudf.DataFrame(y)[0]\n",
    "\n",
    "X_cudf, X_cudf_test, y_cudf, y_cudf_test = train_test_split(X, y, test_size = 0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031556e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset from GPU memory to host memory (CPU)\n",
    "# This is done to later compare CPU and GPU results\n",
    "X_train = X_cudf.to_pandas()\n",
    "X_test = X_cudf_test.to_pandas()\n",
    "y_train = y_cudf.to_pandas()\n",
    "y_test = y_cudf_test.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5847cc25",
   "metadata": {},
   "source": [
    "### Scikit-learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0728a26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.7 s, sys: 3.12 s, total: 25.9 s\n",
      "Wall time: 5.13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=-1, normalize=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ols_sk = skLinearRegression(fit_intercept=True,\n",
    "                            normalize=True,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "ols_sk.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce7eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 320 ms, sys: 274 ms, total: 594 ms\n",
      "Wall time: 74.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predict_sk = ols_sk.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8d68b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.3 ms, sys: 8.48 ms, total: 34.8 ms\n",
      "Wall time: 4.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r2_score_sk = r2_score(y_cudf_test, predict_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4d432",
   "metadata": {},
   "source": [
    "### cuML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33355bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 272 ms, sys: 333 ms, total: 605 ms\n",
      "Wall time: 100 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ols_cuml = cuLinearRegression(fit_intercept=True,\n",
    "                              normalize=True,\n",
    "                              algorithm='eig')\n",
    "\n",
    "ols_cuml.fit(X_cudf, y_cudf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac7e4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 ms, sys: 8.32 ms, total: 38.3 ms\n",
      "Wall time: 37.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predict_cuml = ols_cuml.predict(X_cudf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40191c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 565 µs, sys: 125 µs, total: 690 µs\n",
      "Wall time: 698 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r2_score_cuml = r2_score(y_cudf_test, predict_cuml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5d665",
   "metadata": {},
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a85a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score (SKL):  1.0\n",
      "R^2 score (cuML): 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2 score (SKL):  %s\" % r2_score_sk)\n",
    "print(\"R^2 score (cuML): %s\" % r2_score_cuml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e801b1",
   "metadata": {},
   "source": [
    "### Appendix\n",
    "#### Lifecycle configuration\n",
    "Check for most recent version here: https://github.com/rapidsai/cloud-ml-examples/tree/main/aws/environment_setup"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eca4e4b0",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "set -e\n",
    "\n",
    "sudo -u ec2-user -i <<'EOF'\n",
    "mkdir -p rapids_kernel\n",
    "cd rapids_kernel\n",
    "wget -q https://rapidsai-data.s3.us-east-2.amazonaws.com/conda-pack/rapidsai/rapids0.19_cuda11.0_py3.8.tar.gz\n",
    "echo \"wget completed\"\n",
    "tar -xzf *.gz\n",
    "echo \"unzip completed\"\n",
    "source /home/ec2-user/rapids_kernel/bin/activate\n",
    "conda-unpack \n",
    "echo \"unpack completed\"\n",
    "# optionally install AutoGluon for AutoML GPU demo\n",
    "# source /home/ec2-user/rapids_kernel/bin/activate && pip install --pre autogluon\n",
    "python -m ipykernel install --user --name rapids-19\n",
    "echo \"kernel install completed\"\n",
    "EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-19",
   "language": "python",
   "name": "rapids-19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
