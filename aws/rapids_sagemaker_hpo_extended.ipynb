{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/header.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hyper Parameter Optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization) (HPO) improves model quality by searching over hyperparameters, parameters not typically learned during the training process but rather values that control the learning process itself (e.g., model size/capacity). This search can significantly boost model quality relative to default settings and non-expert tuning; however, HPO can take a very long time on a non-accelerated platform. In this notebook, we containerize a RAPIDS workflow and run Bring-Your-Own-Container SageMaker HPO to show how we can overcome the computational complexity of model search. \n",
    "\n",
    "We accelerate HPO in two key ways: \n",
    "* by *scaling within a node* (e.g., multi-GPU where each GPU brings a magnitude higher core count relative to CPUs), and \n",
    "* by *scaling across nodes* and running parallel trials on cloud instances.\n",
    "\n",
    "By combining these two powers HPO experiments that feel unapproachable and may take multiple days on CPU instances can complete in just hours. For example, we find a <span style=\"color:#8735fb; font-size:14pt\"> **12x** </span> speedup in wall clock time (6 hours vs 3+ days) and a <span style=\"color:#8735fb; font-size:14pt\"> **4.5x** </span> reduction in cost when comparing between GPU and CPU [EC2 Spot instances](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html) on 100 XGBoost HPO trials using 10 parallel workers on 10 years of the Airline Dataset (~63M flights) hosted in a S3 bucket. For additional details refer to the <a href='#experiments'>end of the notebook</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all these powerful tools at our disposal, every data scientist should feel empowered to up-level their model before serving it to the world!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/hpo.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:22pt\"> **Preamble** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get things rolling let's make sure we can query our AWS SageMaker execution role and session as well as our account ID and AWS region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_role = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "\n",
    "account=!(aws sts get-caller-identity --query Account --output text)\n",
    "region=!(aws configure get region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['561241433344'], ['us-east-1'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account, region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:22pt\"> **Key Choices** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and choose the configuration options for our HPO run.\n",
    "\n",
    "Below are two reference configurations showing a small and a large scale HPO (sized in terms of total experiments/compute). \n",
    "\n",
    "The default values in the notebook are set for the small HPO configuration, however you are welcome to scale them up.\n",
    "\n",
    "> **small HPO**: 1_year, XGBoost, 3 CV folds, singleGPU, max_jobs = 10, max_parallel_jobs = 2\n",
    "\n",
    "> **large HPO**: 10_year, XGBoost, 10 CV folds, multiGPU, max_jobs = 100, max_parallel_jobs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ Dataset ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We offer free hosting for several demo datasets that you can try running HPO with, or alternatively you can bring your own dataset (BYOD). \n",
    "\n",
    "By default we leverage the `Airline` dataset, which is a large public tracker of US domestic flight logs which we offer in various sizes (1 year, 3 year, and 10 year) and in <a href='https://parquet.apache.org/'>Parquet</a> (compressed column storage) format. The machine learning objective with this dataset is to predict whether flights will be more than 15 minutes late arriving to their destination ([dataset link](https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&DB_URL=), additional details in <a href='#dataset'>Section 1.1</a>). \n",
    "\n",
    "As an alternative we also offer the `NYC Taxi` dataset which captures yellow cab trip details in Ney York in January 2020, stored in <a href='https://en.wikipedia.org/wiki/Comma-separated_values'>CSV </a> format without any compression. The machine learning objective with this dataset is to predict whether a trip had an above average tip (>$2.20).\n",
    "\n",
    "We host the demo datasets in public S3 demo buckets in both the **us-east-1** (N. Virginia) or **us-west-2** (Oregon) regions (i.e., `sagemaker-rapids-hpo-us-east-1`, and `sagemaker-rapids-hpo-us-west-2`). You should run the SageMaker HPO workflow in either of these two regions if you wish to leverage the demo datasets since SageMaker requires that the S3 dataset and the compute you'll be renting are co-located. \n",
    "\n",
    "Lastly, if you plan to use your own dataset refer to the <a href='#byod'>BYOD checklist in the Appendix</a> to help integrate into the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| dataset | data_bucket | dataset_directory | # samples | storage type | time span |\n",
    "|---|---|---|---|---|---|\n",
    "| Airline Stats Small    | demo    | 1_year   | 6.3M   | Parquet     | 2019         |\n",
    "| Airline Stats Medium   | demo    | 3_year   | 18M    | Parquet     | 2019-2017    |\n",
    "| Airline Stats Large    | demo    | 10_year  | 63M    | Parquet     | 2019-2010    |\n",
    "| NYC Taxi               | demo    | NYC_taxi | 6.3M   | CSV         | 2020 January |\n",
    "| Bring Your Own Dataset | custom  | custom   | custom | Parquet/CSV | custom       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose dataset S3 bucket and directory\n",
    "data_bucket = 'sagemaker-rapids-hpo-' + region[0]\n",
    "dataset_directory = '1_year' # '1_year', '3_year', '10_year', 'NYC_taxi'\n",
    "\n",
    "# please choose output bucket for trained model(s)\n",
    "model_output_bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_input = f\"s3://{data_bucket}/{dataset_directory}\"\n",
    "s3_model_output = f\"s3://{model_output_bucket}/trained-models\"\n",
    "\n",
    "best_hpo_model_local_save_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ Algorithm ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a ML/algorithm perspective, we offer [XGBoost](https://xgboost.readthedocs.io/en/latest/#), [RandomForest](https://docs.rapids.ai/api/cuml/stable/cuml_blogs.html#tree-and-forest-models) and [KMeans](https://docs.rapids.ai/api/cuml/stable/api.html?highlight=kmeans#cuml.KMeans). You are free to switch between these algorithm choices and everything in the example will continue to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose learning algorithm\n",
    "algorithm_choice = 'XGBoost'\n",
    "\n",
    "assert (algorithm_choice in ['XGBoost', 'RandomForest', 'KMeans'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also optionally increase robustness via reshuffles of the train-test split (i.e., [cross-validation folds](https://scikit-learn.org/stable/modules/cross_validation.html)). Typical values here are between 3 and 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose cross-validation folds\n",
    "cv_folds = 3\n",
    "\n",
    "assert (cv_folds >= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ ML Workflow Compute Choice ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable the option of running different code variations that unlock increasing amounts of parallelism in the compute workflow. \n",
    "\n",
    "* `singleCPU`** = [pandas](https://pandas.pydata.org/) + [sklearn](https://scikit-learn.org/stable/)\n",
    "* `multiCPU`   = [dask](https://dask.org/) + [pandas](https://pandas.pydata.org/) + [sklearn](https://scikit-learn.org/stable/)\n",
    "\n",
    "* <span style=\"color:#8735fb; font-size:14pt\"> RAPIDS </span> `singleGPU` = [cudf](https://github.com/rapidsai/cudf) + [cuml](https://github.com/rapidsai/cuml)\n",
    "* <span style=\"color:#8735fb; font-size:14pt\"> RAPIDS </span> `multiGPU`  = [dask](https://dask.org/) + [cudf](https://github.com/rapidsai/cudf) + [cuml](https://github.com/rapidsai/cuml) \n",
    "\n",
    "All of these code paths are available in the `/code/workflows` directory for your reference. \n",
    "\n",
    "> **Note that the single-CPU option will leverage multiple cores in the model training portion of the workflow; however, to unlock full parallelism in each stage of the workflow we use [Dask](https://dask.org/). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose code variant\n",
    "ml_workflow_choice = 'singleGPU' \n",
    "\n",
    "assert (ml_workflow_choice in ['singleCPU', 'singleGPU', 'multiCPU', 'multiGPU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ Search Ranges and Strategy ] </span>\n",
    "<a id='strategy-and-param-ranges'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important choices when running HPO is to choose the bounds of the hyperparameter search process. Below we've set the ranges of the hyperparameters to allow for interesting variation, you are of course welcome to revise these ranges based on domain knowledge especially if you plan to plug in your own dataset. \n",
    "\n",
    "> Note that we support additional algorithm specific parameters (refer to the `parse_hyper_parameter_inputs` function in `HPOConfig.py`), but for demo purposes have limited our choice to the three parameters that overlap between the XGBoost and RandomForest algorithms. For more details see the documentation for [XGBoost parameters](https://xgboost.readthedocs.io/en/latest/parameter.html) and [RandomForest parameters](https://docs.rapids.ai/api/cuml/stable/api.html#random-forest). Since KMeans uses different parameters, we adjust accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose HPO search ranges\n",
    "hyperparameter_ranges = {\n",
    "    'max_depth'    : sagemaker.parameter.IntegerParameter        ( 5, 15 ),\n",
    "    'n_estimators' : sagemaker.parameter.IntegerParameter        ( 100, 500 ),\n",
    "    'max_features' : sagemaker.parameter.ContinuousParameter     ( 0.1, 1.0 ),    \n",
    "} # see note above for adding additional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'XGBoost' in algorithm_choice: \n",
    "    # number of trees parameter name difference b/w XGBoost and RandomForest\n",
    "    hyperparameter_ranges['num_boost_round'] = hyperparameter_ranges.pop('n_estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'KMeans' in algorithm_choice:\n",
    "    hyperparameter_ranges = {\n",
    "        'n_clusters' : sagemaker.parameter.IntegerParameter     ( 2, 20 ), \n",
    "        'max_iter'   : sagemaker.parameter.IntegerParameter     ( 100, 500 ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also choose between a Random and Bayesian search strategy for picking parameter combinations. \n",
    "\n",
    "**Random Search**: Choose a random combination of values from within the ranges for each training job it launches. The choice of hyperparameters doesn't depend on previous results so you can run the maximum number of concurrent workers without affecting the performance of the search. \n",
    "\n",
    "**Bayesian Search**: Make a guess about which hyperparameter combinations are likely to get the best results. After testing the first set of hyperparameter values, hyperparameter tuning uses regression to choose the next set of hyperparameter values to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose HPO search strategy\n",
    "search_strategy = 'Random'\n",
    "\n",
    "assert (search_strategy in ['Random', 'Bayesian'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ Experiment Scale ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to decide how may total experiments to run, and how many should run in parallel. Below we have a very conservative number of maximum jobs to run so that you don't accidently spawn large computations when starting out, however for meaningful HPO searches this number should be much higher (e.g., in our experiments we often run 100 max_jobs). Note that you may need to request a [quota limit increase](https://docs.aws.amazon.com/general/latest/gr/sagemaker.html) for additional  `max_parallel_jobs` parallel workers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose total number of HPO experiments[ we have set this number very low to allow for automated CI testing ]\n",
    "max_jobs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose number of experiments that can run in parallel\n",
    "max_parallel_jobs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also set the max duration for an individual job to 24 hours so we don't have run-away compute jobs taking too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration_of_experiment_seconds = 60 * 60 * 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> [ Compute Platform ] </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the dataset size and compute choice we will try to recommend an instance choice*, you are of course welcome to select alternate configurations. \n",
    "> e.g., For the 10_year dataset option, we suggest ml.p3.8xlarge instances (4 GPUs) and ml.m5.24xlarge CPU instances ( we will need upwards of 200GB CPU RAM during model training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommended instance type : ml.p3.2xlarge \n",
      "instance details          : 1x GPU [ V100 ], 16GB GPU memory, 61GB CPU memory\n"
     ]
    }
   ],
   "source": [
    "# we will recommend a compute instance type, feel free to modify \n",
    "instance_type = recommend_instance_type(ml_workflow_choice, dataset_directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to choosing our instance type, we can also enable significant savings by leveraging [AWS EC2 Spot Instances](https://aws.amazon.com/ec2/spot/).\n",
    "\n",
    "We **highly recommend** that you set this flag to `True` as it typically leads to 60-70% cost savings. Note, however that you may need to request a [quota limit increase](https://docs.aws.amazon.com/general/latest/gr/sagemaker.html) to enable Spot instances in SageMaker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please choose whether spot instances should be used\n",
    "use_spot_instances_flag = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:22pt\"> **Validate** </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 data input    =\ts3://sagemaker-rapids-hpo-us-east-1/1_year\n",
      "s3 model output  =\ts3://sagemaker-us-east-1-561241433344/trained-models\n",
      "compute          =\tsingleGPU\n",
      "algorithm        =\tXGBoost, 3 cv-fold\n",
      "instance         =\tml.p3.2xlarge\n",
      "spot instances   =\tTrue\n",
      "hpo strategy     =\tRandom\n",
      "max_experiments  =\t2\n",
      "max_parallel     =\t2\n",
      "max runtime      =\t86400 sec\n"
     ]
    }
   ],
   "source": [
    "summarize_choices(s3_data_input, s3_model_output, ml_workflow_choice, algorithm_choice, \n",
    "                  cv_folds, instance_type, use_spot_instances_flag, search_strategy, \n",
    "                  max_jobs, max_parallel_jobs, max_duration_of_experiment_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"display: block; text-align: center; color:#8735fb; font-size:30pt\"> **1. ML Workflow** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/ml_workflow.png' width='800'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 1.1 - Dataset </span>\n",
    "<a id ='dataset'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default settings for this demo are built to utilize the Airline dataset (Carrier On-Time Performance 1987-2020, available from the [Bureau of Transportation Statistics](https://transtats.bts.gov/Tables.asp?DB_ID=120&DB_Name=Airline%20On-Time%20Performance%20Data&DB_Short_Name=On-Time#)). Below are some additional details about this dataset, we plan to offer a companion notebook that does a deep dive on the data science behind this dataset. Note that if you are using an alternate dataset (e.g., NYC Taxi or BYOData) these details are not relevant.\n",
    "\n",
    "The public dataset contains logs/features about flights in the United States (17 airlines) including:\n",
    "\n",
    "* Locations and distance  ( `Origin`, `Dest`, `Distance` )\n",
    "* Airline / carrier ( `Reporting_Airline` )\n",
    "* Scheduled departure and arrival times ( `CRSDepTime` and `CRSArrTime` )\n",
    "* Actual departure and arrival times ( `DpTime` and `ArrTime` )\n",
    "* Difference between scheduled & actual times ( `ArrDelay` and `DepDelay` )\n",
    "* Binary encoded version of late, aka our target variable ( `ArrDelay15` )\n",
    "\n",
    "Using these features we will build a classifier model to predict whether a flight is going to be more than 15 minutes late on arrival as it prepares to depart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 1.2 - Python ML Workflow </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a RAPIDS enabled SageMaker HPO we first need to build a [SageMaker Estimator](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html). An Estimator is a container image that captures all the software needed to run an HPO experiment. The container is augmented with entrypoint code that will be trggered at runtime by each worker. The entrypoint code enables us to write custom models and hook them up to data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with SageMaker HPO, the entrypoint logic should parse hyperparameters (supplied by AWS SageMaker), load and split data, build and train a model, score/evaluate the trained model, and emit an output representing the final score for the given hyperparameter setting. We've already built multiple variations of this code.\n",
    "\n",
    "If you would like to make changes by adding your custom model logic feel free to modify the **train.py** and/or the specific workflow files in the `code/workflows` directory. You are also welcome to uncomment the cells below to load the read/review the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's switch our working directory to the location of the Estimator entrypoint and library code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/updated/cloud-ml-examples/aws/code\n"
     ]
    }
   ],
   "source": [
    "%cd code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "aws/code\n",
    "├── Dockerfile\n",
    "├── entrypoint.sh\n",
    "├── HPOConfig.py\n",
    "├── HPODatasets.py\n",
    "├── MLWorkflow.py\n",
    "├── serve.py\n",
    "├── train.py\n",
    "└── workflows\n",
    "    ├── MLWorkflowMultiCPU.py\n",
    "    ├── MLWorkflowMultiGPU.py\n",
    "    ├── MLWorkflowSingleCPU.py\n",
    "    └── MLWorkflowSingleGPU.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load workflows/MLWorkflowSingleGPU.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"display: block; text-align: center; color:#8735fb; font-size:30pt\"> **2. Build Estimator** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/estimator.png' width='800'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've already mentioned, the SageMaker Estimator represents the containerized software stack that AWS SageMaker will replicate to each worker node.\n",
    "\n",
    "The first step to building our Estimator, is to augment a RAPIDS container with our ML Workflow code from above, and push this image to Amazon Elastic Cloud Registry so it is available to SageMaker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 2.1 - Containerize and Push to ECR </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn to building our container so that it can integrate with the AWS SageMaker HPO API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our container can either be built on top of the latest RAPIDS [ nightly ] image as a starting layer or the RAPIDS stable image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapids_base_container = 'rapidsai/rapidsai-cloud-ml:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also decide on the full name of our container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_base = 'cloud-ml-sagemaker'\n",
    "image_tag  = rapids_base_container.split(':')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_fullname = f\"{account[0]}.dkr.ecr.{region[0]}.amazonaws.com/{image_base}:{image_tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'561241433344.dkr.ecr.us-east-1.amazonaws.com/cloud-ml-sagemaker:latest'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecr_fullname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> 2.1.1 - Write Dockerfile </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write out the Dockerfile to disk, and in a few cells execute the docker build command. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write our selected RAPDIS image layer as the first FROM statement in the the Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dockerfile', 'w') as dockerfile: \n",
    "    dockerfile.writelines( f'FROM {rapids_base_container} \\n\\n'\n",
    "                           f'ENV AWS_DATASET_DIRECTORY=\"{dataset_directory}\"\\n'\n",
    "                           f'ENV AWS_ALGORITHM_CHOICE=\"{algorithm_choice}\"\\n'\n",
    "                           f'ENV AWS_ML_WORKFLOW_CHOICE=\"{ml_workflow_choice}\"\\n'\n",
    "                           f'ENV AWS_CV_FOLDS=\"{cv_folds}\"\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's append write the remaining pieces of the Dockerfile, namely adding the sagemaker-training-toolkit, flask, dask-ml, and copying our python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a Dockerfile\n",
    "\n",
    "# ensure printed output/log-messages retain correct order\n",
    "ENV PYTHONUNBUFFERED=True\n",
    "\n",
    "# path where SageMaker looks for code when container runs in the cloud\n",
    "ENV CLOUD_PATH=\"/opt/ml/code\"\n",
    "\n",
    "# copy our latest [local] code into the container \n",
    "COPY . $CLOUD_PATH\n",
    "\n",
    "# make the entrypoint script executable\n",
    "RUN chmod +x $CLOUD_PATH/entrypoint.sh\n",
    "\n",
    "WORKDIR $CLOUD_PATH\n",
    "ENTRYPOINT [\"./entrypoint.sh\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's ensure that our Dockerfile correctly captured our base image selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM rapidsai/rapidsai-cloud-ml:latest \n",
      "\n",
      "ENV AWS_DATASET_DIRECTORY=\"1_year\"\n",
      "ENV AWS_ALGORITHM_CHOICE=\"XGBoost\"\n",
      "ENV AWS_ML_WORKFLOW_CHOICE=\"singleGPU\"\n",
      "ENV AWS_CV_FOLDS=\"3\"\n",
      "\n",
      "# ensure printed output/log-messages retain correct order\n",
      "ENV PYTHONUNBUFFERED=True\n",
      "\n",
      "# path where SageMaker looks for code when container runs in the cloud\n",
      "ENV CLOUD_PATH=\"/opt/ml/code\"\n",
      "\n",
      "# copy our latest [local] code into the container \n",
      "COPY . $CLOUD_PATH\n",
      "\n",
      "# make the entrypoint script executable\n",
      "RUN chmod +x $CLOUD_PATH/entrypoint.sh\n",
      "\n",
      "WORKDIR $CLOUD_PATH\n",
      "ENTRYPOINT [\"./entrypoint.sh\"]\n"
     ]
    }
   ],
   "source": [
    "validate_dockerfile(rapids_base_container)\n",
    "!cat Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> 2.1.2 Build and Tag </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The build step will be dominated by the download of the RAPIDS image (base layer). If it's already been downloaded the build will take less than 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest: Pulling from rapidsai/rapidsai-cloud-ml\n",
      "Digest: sha256:a6e630882b0a93078acc2e8d0956f860fb69e7bdeb0dd535cbbded95923e84f6\n",
      "Status: Image is up to date for rapidsai/rapidsai-cloud-ml:latest\n",
      "docker.io/rapidsai/rapidsai-cloud-ml:latest\n"
     ]
    }
   ],
   "source": [
    "!docker pull $rapids_base_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  81.41kB\n",
      "Step 1/11 : FROM rapidsai/rapidsai-cloud-ml:latest\n",
      " ---> 8f6c5be64e10\n",
      "Step 2/11 : ENV AWS_DATASET_DIRECTORY=\"1_year\"\n",
      " ---> Using cache\n",
      " ---> 273dcc58515d\n",
      "Step 3/11 : ENV AWS_ALGORITHM_CHOICE=\"XGBoost\"\n",
      " ---> Running in d3f64939f804\n",
      "Removing intermediate container d3f64939f804\n",
      " ---> d71543e6b46c\n",
      "Step 4/11 : ENV AWS_ML_WORKFLOW_CHOICE=\"singleGPU\"\n",
      " ---> Running in 71ad202537c0\n",
      "Removing intermediate container 71ad202537c0\n",
      " ---> 48d19f4b6d5b\n",
      "Step 5/11 : ENV AWS_CV_FOLDS=\"3\"\n",
      " ---> Running in 70b072916ecc\n",
      "Removing intermediate container 70b072916ecc\n",
      " ---> 4f1056add9ac\n",
      "Step 6/11 : ENV PYTHONUNBUFFERED=True\n",
      " ---> Running in d8ab016b42e2\n",
      "Removing intermediate container d8ab016b42e2\n",
      " ---> 6c5eb758c72b\n",
      "Step 7/11 : ENV CLOUD_PATH=\"/opt/ml/code\"\n",
      " ---> Running in 3a03105dd166\n",
      "Removing intermediate container 3a03105dd166\n",
      " ---> 57c3c914bbf4\n",
      "Step 8/11 : COPY . $CLOUD_PATH\n",
      " ---> 777175551f2c\n",
      "Step 9/11 : RUN chmod +x $CLOUD_PATH/entrypoint.sh\n",
      " ---> Running in 6339515dee21\n",
      "Removing intermediate container 6339515dee21\n",
      " ---> dc8138b2dedb\n",
      "Step 10/11 : WORKDIR $CLOUD_PATH\n",
      " ---> Running in e834a8c89535\n",
      "Removing intermediate container e834a8c89535\n",
      " ---> 81fe20d249df\n",
      "Step 11/11 : ENTRYPOINT [\"./entrypoint.sh\"]\n",
      " ---> Running in 5094e5dcafd1\n",
      "Removing intermediate container 5094e5dcafd1\n",
      " ---> 32370a153006\n",
      "Successfully built 32370a153006\n",
      "Successfully tagged 561241433344.dkr.ecr.us-east-1.amazonaws.com/cloud-ml-sagemaker:latest\n",
      "CPU times: user 77.7 ms, sys: 18.8 ms, total: 96.5 ms\n",
      "Wall time: 4.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!docker build . -t $ecr_fullname -f Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> 2.1.3 - Publish to Elastic Cloud Registry (ECR) </span>\n",
    "\n",
    "Now that we've built and tagged our container its time to push it to Amazon's container registry (ECR). Once in ECR, AWS SageMaker will be able to leverage our image to build Estimators and run experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker Login to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_login_str = !(aws ecr get-login --region {region[0]} --no-include-email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!{docker_login_str[0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ECR repository [ if it doesn't already exist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_query = !(aws ecr describe-repositories --repository-names $image_base)\n",
    "if repository_query[0] == '':\n",
    "    !(aws ecr create-repository --repository-name $image_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now actually push the container to ECR\n",
    "> Note the first push to ECR may take some time (hopefully less than 10 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [561241433344.dkr.ecr.us-east-1.amazonaws.com/cloud-ml-sagemaker]\n",
      "\n",
      "\u001b[1B149b4cf4: Preparing \n",
      "\u001b[1B24a12a18: Preparing \n",
      "\u001b[1Bd318c93c: Preparing \n",
      "\u001b[1B32fbf55b: Preparing \n",
      "\u001b[1B189ca3a3: Preparing \n",
      "\u001b[1Bb97c445b: Preparing \n",
      "\u001b[1B78e3bf48: Preparing \n",
      "\u001b[1B8b120579: Preparing \n",
      "\u001b[1B87e0621d: Preparing \n",
      "\u001b[1B7ad6008c: Preparing \n",
      "\u001b[1Bdd8ed907: Preparing \n",
      "\u001b[1B872b888e: Preparing \n",
      "\u001b[1B512fd434: Preparing \n",
      "\u001b[1B31fc0e08: Preparing \n",
      "\u001b[15B49b4cf4: Pushed lready exists 4kB2A\u001b[2K\u001b[14A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[14A\u001b[2K\u001b[15A\u001b[2Klatest: digest: sha256:a73731d0ecb1bca82bed60f21561740ed9c42f581ca000a8388d0c920e92e260 size: 3475\n"
     ]
    }
   ],
   "source": [
    "!docker push $ecr_fullname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 2.2 - Create Estimator </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having built our container [ +custom logic] and pushed it to ECR, we can finally compile all of efforts into an Estimator instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'volume_size' - EBS volume size in GB, default = 30\n",
    "estimator_params = {\n",
    "    'image_uri': ecr_fullname,\n",
    "    'role': execution_role,    \n",
    "    \n",
    "    'instance_type': instance_type,\n",
    "    'instance_count': 1,\n",
    "    \n",
    "    'input_mode': 'File',\n",
    "    'output_path': s3_model_output,\n",
    "    \n",
    "    'use_spot_instances': use_spot_instances_flag,\n",
    "    \n",
    "    'max_run': max_duration_of_experiment_seconds, # 24 hours \n",
    "    'sagemaker_session': session,\n",
    "}\n",
    "\n",
    "if use_spot_instances_flag == True:\n",
    "    estimator_params.update({'max_wait' : max_duration_of_experiment_seconds + 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(**estimator_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 2.3 - Test Estimator </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to test by asking SageMaker to run the BYOContainer logic inside our Estimator. This is a useful step if you've made changes to your custom logic and are interested in making sure everything works before launching a large HPO search. \n",
    "\n",
    "> Note: This verification step will use the default hyperparameter values declared in our custom train code, as SageMaker HPO will not be orchestrating a search for this single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 data input    =\ts3://sagemaker-rapids-hpo-us-east-1/1_year\n",
      "s3 model output  =\ts3://sagemaker-us-east-1-561241433344/trained-models\n",
      "compute          =\tsingleGPU\n",
      "algorithm        =\tXGBoost, 3 cv-fold\n",
      "instance         =\tml.p3.2xlarge\n",
      "spot instances   =\tTrue\n",
      "hpo strategy     =\tRandom\n",
      "max_experiments  =\t2\n",
      "max_parallel     =\t2\n",
      "max runtime      =\t86400 sec\n"
     ]
    }
   ],
   "source": [
    "summarize_choices(s3_data_input, s3_model_output, ml_workflow_choice, algorithm_choice, \n",
    "                  cv_folds, instance_type, use_spot_instances_flag, search_strategy, \n",
    "                  max_jobs, max_parallel_jobs, max_duration_of_experiment_seconds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated job name : air-sGPU-XGB-3cv-1722781c24aa0e4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_name = new_job_name_from_config(dataset_directory, region, ml_workflow_choice, \n",
    "                                    algorithm_choice, cv_folds,\n",
    "                                    instance_type  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-22 18:49:23 Starting - Starting the training job...\n",
      "2021-06-22 18:49:39 Starting - Launching requested ML instancesProfilerReport-1624387762: InProgress\n",
      "......\n",
      "2021-06-22 18:50:41 Starting - Insufficient capacity error from EC2 while launching instances, retrying!.........\n",
      "2021-06-22 18:52:21 Starting - Preparing the instances for training......\n",
      "2021-06-22 18:53:24 Downloading - Downloading input data...\n",
      "2021-06-22 18:53:41 Training - Downloading the training image.....................\n",
      "2021-06-22 18:57:23 Training - Training image download completed. Training in progress.\u001b[34m@ entrypoint -> launching training script \n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:11,736     INFO hpo_log \u001b[0m\n",
      "\u001b[34mparsing configuration from environment settings...\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:11,736     INFO hpo_log   Dataset: Airline\n",
      "  Compute: single-GPU\n",
      "  Algorithm: XGBoost\n",
      "  CV_folds: 3\n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:11,736     INFO hpo_log parsing model hyperparameters from command line arguments...log\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:11,740     INFO hpo_log {    'gamma': 0.0,\n",
      "     'lambda': 1,\n",
      "     'learning_rate': 0.3,\n",
      "     'max_depth': 5,\n",
      "     'num_boost_round': 10,\n",
      "     'objective': 'binary:logistic',\n",
      "     'random_state': 0,\n",
      "     'seed': 0,\n",
      "     'tree_method': 'gpu_hist',\n",
      "     'verbosity': 0}\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:11,742     INFO hpo_log Parquet input files detected\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/training/part.4.parquet',\n",
      " '/opt/ml/input/data/training/part.12.parquet',\n",
      " '/opt/ml/input/data/training/part.1.parquet',\n",
      " '/opt/ml/input/data/training/part.11.parquet',\n",
      " '/opt/ml/input/data/training/part.10.parquet',\n",
      " '/opt/ml/input/data/training/part.2.parquet',\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:11,742     INFO hpo_log detected 13 files as input\n",
      " '/opt/ml/input/data/training/part.6.parquet',\n",
      " '/opt/ml/input/data/training/part.5.parquet',\n",
      " '/opt/ml/input/data/training/part.9.parquet',\n",
      " '/opt/ml/input/data/training/part.0.parquet',\n",
      " '/opt/ml/input/data/training/part.3.parquet',\n",
      " '/opt/ml/input/data/training/part.8.parquet',\n",
      " '/opt/ml/input/data/training/part.7.parquet']\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:17,906     INFO hpo_log Single-GPU Workflow \n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:22,548     INFO hpo_log ingested Parquet dataset; shape = (6763388, 14)\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:22,549     INFO hpo_log  --- ingest_data completed in 4.64196 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:22,571     INFO hpo_log  --- handle_missing_data completed in 0.02190 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:22,571     INFO hpo_log > train-test split\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:24,538     INFO hpo_log  --- split_dataset completed in 1.96760 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:24,538     INFO hpo_log > fit xgboost model\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:25,499     INFO hpo_log  --- fit completed in 0.96067 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:25,499     INFO hpo_log predict with trained model \u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:25,541     INFO hpo_log  --- predict completed in 0.04142 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,684     INFO hpo_log score = 0.92024\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,684     INFO hpo_log  --- score completed in 1.14288 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,684     INFO hpo_log saving high-scoring model\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,686     INFO hpo_log end of cv-fold \n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,686     INFO hpo_log skipping ingestion, using cache\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,686     INFO hpo_log  --- ingest_data completed in 0.00007 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,713     INFO hpo_log  --- handle_missing_data completed in 0.01510 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,713     INFO hpo_log > train-test split\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,765     INFO hpo_log  --- split_dataset completed in 0.05172 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:26,777     INFO hpo_log > fit xgboost model\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,122     INFO hpo_log  --- fit completed in 0.34510 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,124     INFO hpo_log predict with trained model \u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,157     INFO hpo_log  --- predict completed in 0.03302 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,169     INFO hpo_log score = 0.9203\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,169     INFO hpo_log  --- score completed in 0.01161 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,169     INFO hpo_log saving high-scoring model\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,170     INFO hpo_log end of cv-fold \n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,170     INFO hpo_log skipping ingestion, using cache\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,170     INFO hpo_log  --- ingest_data completed in 0.00006 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,196     INFO hpo_log  --- handle_missing_data completed in 0.01470 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,196     INFO hpo_log > train-test split\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,247     INFO hpo_log  --- split_dataset completed in 0.05088 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,260     INFO hpo_log > fit xgboost model\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,608     INFO hpo_log  --- fit completed in 0.34838 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,610     INFO hpo_log predict with trained model \u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,641     INFO hpo_log  --- predict completed in 0.03119 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,654     INFO hpo_log score = 0.92005\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,654     INFO hpo_log  --- score completed in 0.01301 s\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,654     INFO hpo_log end of cv-fold \n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,655     INFO hpo_log total_time = 9.74796 s \u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,655     INFO hpo_log cv-fold scores : [0.9202431440353394, 0.9202974438667297, 0.9200503826141357] \n",
      "\u001b[0m\n",
      "\u001b[34m2021-06-22 18:57:27,655     INFO hpo_log final-score: 0.9201969901720682; \n",
      "\u001b[0m\n",
      "\n",
      "2021-06-22 18:57:43 Uploading - Uploading generated training model\n",
      "2021-06-22 18:57:43 Completed - Training job completed\n",
      "Training seconds: 255\n",
      "Billable seconds: 76\n",
      "Managed Spot Training savings: 70.2%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs = s3_data_input, job_name = job_name.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"display: block; text-align: center; color:#8735fb; font-size:30pt\"> **3. Run HPO** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a working SageMaker Estimator in hand, the hardest part is behind us. In the key choices section we <a href='#strategy-and-param-ranges'>already defined our search strategy and hyperparameter ranges</a>, so all that remains is to choose a metric to evaluate performance on. For more documentation check out the AWS SageMaker [Hyperparameter Tuner documentation](https://sagemaker.readthedocs.io/en/stable/tuner.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/run_hpo.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.1 - Define Metric </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only focus on a single metric, which we call 'final-score', that captures the accuracy of our model on the test data unseen during training. You are of course welcome to add aditional metrics, see [AWS SageMaker documentation on Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-define-metrics.html). When defining a metric we provide a regular expression (i.e., string parsing rule) to extract the key metric from the output of each Estimator/worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [{'Name': 'final-score', 'Regex': 'final-score: (.*);'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = 'final-score'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.2 - Define Tuner </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we put all of the elements we've been building up together into a HyperparameterTuner declaration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo = sagemaker.tuner.HyperparameterTuner(estimator=estimator,\n",
    "                                          metric_definitions=metric_definitions, \n",
    "                                          objective_metric_name=objective_metric_name,\n",
    "                                          objective_type='Maximize',\n",
    "                                          hyperparameter_ranges=hyperparameter_ranges,\n",
    "                                          strategy=search_strategy,  \n",
    "                                          max_jobs=max_jobs,\n",
    "                                          max_parallel_jobs=max_parallel_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.3 - Run HPO </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3 data input    =\ts3://sagemaker-rapids-hpo-us-east-1/1_year\n",
      "s3 model output  =\ts3://sagemaker-us-east-1-561241433344/trained-models\n",
      "compute          =\tsingleGPU\n",
      "algorithm        =\tXGBoost, 3 cv-fold\n",
      "instance         =\tml.p3.2xlarge\n",
      "spot instances   =\tTrue\n",
      "hpo strategy     =\tRandom\n",
      "max_experiments  =\t2\n",
      "max_parallel     =\t2\n",
      "max runtime      =\t86400 sec\n"
     ]
    }
   ],
   "source": [
    "summarize_choices( s3_data_input, s3_model_output, ml_workflow_choice, algorithm_choice, \n",
    "                   cv_folds, instance_type, use_spot_instances_flag, search_strategy, \n",
    "                   max_jobs, max_parallel_jobs, max_duration_of_experiment_seconds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be sure we take a moment to confirm before launching all of our HPO experiments. Depending on your configuration options running this cell can kick off a massive amount of computation!\n",
    "> Once this process begins, we recommend that you use the SageMaker UI to keep track of the <a href='../img/gpu_hpo_100x10.png'>health of the HPO process and the individual workers</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated job name : air-sGPU-XGB-3cv-6348eae0c13e966\n",
      "\n",
      "..................................................................................................................................................................................................................................................................................................................................................................!\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "tuning_job_name = new_job_name_from_config(dataset_directory, region, ml_workflow_choice, \n",
    "                                           algorithm_choice, cv_folds, \n",
    "                                           instance_type)\n",
    "hpo.fit( inputs=s3_data_input,\n",
    "         job_name=tuning_job_name,\n",
    "         wait=True,\n",
    "         logs='All')\n",
    "\n",
    "hpo.wait()  # block until the .fit call above is completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.4 - Results and Summary </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your job is complete there are multiple ways to analyze the results.\n",
    "Below we display the performance of the best job, as well printing each HPO trial/job as a row of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.9194109439849854\n",
      "best params: {'max_depth': '13', 'max_features': '0.3530016670218563', 'num_boost_round': '333'}\n",
      "best job-name: air-sGPU-XGB-3cv-6348eae0c13e966-002-8f0a31f3\n"
     ]
    }
   ],
   "source": [
    "hpo_results = summarize_hpo_results(tuning_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>num_boost_round</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.353002</td>\n",
       "      <td>333.0</td>\n",
       "      <td>air-sGPU-XGB-3cv-6348eae0c13e966-002-8f0a31f3</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.919411</td>\n",
       "      <td>2021-06-22 19:21:11+00:00</td>\n",
       "      <td>2021-06-22 19:25:31+00:00</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.713760</td>\n",
       "      <td>110.0</td>\n",
       "      <td>air-sGPU-XGB-3cv-6348eae0c13e966-001-cd717529</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.919040</td>\n",
       "      <td>2021-06-22 19:05:30+00:00</td>\n",
       "      <td>2021-06-22 19:09:46+00:00</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  max_features  num_boost_round  \\\n",
       "0       13.0      0.353002            333.0   \n",
       "1       13.0      0.713760            110.0   \n",
       "\n",
       "                                 TrainingJobName TrainingJobStatus  \\\n",
       "0  air-sGPU-XGB-3cv-6348eae0c13e966-002-8f0a31f3         Completed   \n",
       "1  air-sGPU-XGB-3cv-6348eae0c13e966-001-cd717529         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0             0.919411 2021-06-22 19:21:11+00:00 2021-06-22 19:25:31+00:00   \n",
       "1             0.919040 2021-06-22 19:05:30+00:00 2021-06-22 19:09:46+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                       260.0  \n",
       "1                       256.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name).dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For a more in depth look at the HPO process we invite you to check out the <a href='https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning/analyze_results'>HPO_Analyze_TuningJob_Results.ipynb</a> notebook which shows how we can explore interesting things like the <a href='img/results_analysis.png'>impact of each individual hyperparameter on the performance metric</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.5 - Getting the best Model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's download the best trained model from our HPO runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded best model\n",
      "> filename: /home/ec2-user/SageMaker/updated/cloud-ml-examples/aws/best_model.tar.gz\n",
      "> local directory : /home/ec2-user/SageMaker/updated/cloud-ml-examples/aws\n",
      "\n",
      "full S3 path : s3://sagemaker-us-east-1-561241433344/trained-models/air-sGPU-XGB-3cv-6348eae0c13e966-002-8f0a31f3/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "local_filename, s3_path_to_best_model = download_best_model(model_output_bucket, s3_model_output,\n",
    "                                                            hpo_results, best_hpo_model_local_save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:20pt\"> 3.6 - Model Serving </span>\n",
    "\n",
    "With your best model in hand, you can now move on to [serving this model on SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html). \n",
    "\n",
    "In the example below we show you how to build a [RealTimePredictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html) using the best model found during the HPO search. We will add a lightweight Flask server to our RAPIDS Estimator (a.k.a., container) which will handle the incoming requests and pass them along to the trained model for inference. If you are curious about how this works under the hood check out the [Use Your Own Inference Server](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html) documentation and reference the code in `code/serve.py`.\n",
    "\n",
    "If you are interested in additional serving options (e.g., large batch with batch-transform), we plan to add a companion notebook that will provide additional details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:18pt\"> 3.6.1 - GPU serving </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_model = sagemaker.model.Model(image_uri=ecr_fullname, \n",
    "                                       role=execution_role, \n",
    "                                       model_data=s3_path_to_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kick off an instance for prediction [ recommend 'ml.g4dn.2xlarge' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------!"
     ]
    }
   ],
   "source": [
    "DEMO_SERVING_FLAG = True\n",
    "\n",
    "if DEMO_SERVING_FLAG:\n",
    "    endpoint_model.deploy(initial_instance_count=1,\n",
    "                          instance_type='ml.p3.8xlarge') # 'ml.g4dn.2xlarge') #'ml.p3.2xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the prediction and return the result(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we've compiled examples to sanity test the trained model performance on the Airline dataset.\n",
    "> The first example is from a 2019 flight that departed nine minutes early, \n",
    "\n",
    "> The second example is from a 2018 flight that was more than two hours late to depart.\n",
    "\n",
    "When we run these samples we expect to see **b'[0.0, 1.0]** as the printed result.\n",
    "\n",
    "We encourage you to modify the queries below especially if you plug in your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[0.0, 1.0]'\n"
     ]
    }
   ],
   "source": [
    "if DEMO_SERVING_FLAG:\n",
    "    \n",
    "    predictor = sagemaker.predictor.Predictor(\n",
    "        endpoint_name=str(endpoint_model.endpoint_name), \n",
    "        sagemaker_session=session\n",
    "    )\n",
    "\n",
    "    if dataset_directory in ['1_year', '3_year', '10_year']:\n",
    "        on_time_example = [2019.0, 4.0, 12.0, 2.0, 3647.0, 20452.0, 30977.0, 33244.0, 1943.0, -9.0, 0.0, 75.0, 491.0] # 9 minutes early departure\n",
    "        late_example = [2018.0, 3.0, 9.0, 5.0, 2279.0, 20409.0, 30721.0, 31703.0, 733.0, 123.0, 1.0, 61.0, 200.0]\n",
    "        example_payload = str(list([on_time_example, late_example]))\n",
    "    else:\n",
    "        example_payload = '' # fill in a sample payload\n",
    "    \n",
    "    result = predictor.predict(example_payload)\n",
    "    print( result )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are finished with the serving example, we should be sure to clean up and delete the endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEMO_SERVING_FLAG:\n",
    "    \n",
    "    predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:25pt\"> **Summary** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now successfully built a RAPIDS ML workflow, containerized it (as a SageMaker Estimator), and launched a set of HPO experiments to find the best hyperparamters for our model.\n",
    "\n",
    "If you are curious to go further, we invite you to plug in your own dataset and tweak the configuration settings to find your champion model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HPO Experiment Details**\n",
    "<a id='experiments'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the introduction we find a <span style=\"color:#8735fb; font-size:14pt\"> **12X** </span> speedup in wall clock time and a <span style=\"color:#8735fb; font-size:14pt\"> **4.5x** </span> reduction in cost when comparing between GPU and CPU instances on 100 HPO trials using 10 parallel workers on 10 years of the Airline Dataset (~63M flights). In these experiments we used the XGBoost algorithm with the multi-GPU vs multi-CPU Dask cluster and 10 cross validaiton folds. Below we offer a table with additional details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/results.png' width='70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the CPU runs, 12 jobs were stopped since they exceeded the 24 hour limit we set. <a href='img/cpu_hpo_100x10.png'>CPU Job Summary Image</a>\n",
    "\n",
    "In the case of the GPU runs, no jobs were stopped. <a href='img/gpu_hpo_100x10.png'>GPU Job Summary Image</a>\n",
    "\n",
    "Note that in both cases 1 job failed because a spot instance was terminated. But 1 failed job out of 100 is a minimal tradeoff for the significant cost savings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension 1: SHAP Interpretability\n",
    "# Extension 2: BringYourOwnDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"display: block; color:#8735fb; font-size:25pt\"> **Appendix: Bring Your Own Dataset Checklist** </span>\n",
    "<a id ='byod'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan to use your own dataset (BYOD) here is a checklist to help you integrate into the workflow:\n",
    "\n",
    "> - [ ] Dataset should be in either CSV or Parquet format.\n",
    "> - [ ] Dataset is already pre-processed (and all feature-engineering is done).\n",
    "> - [ ] Dataset is uploaded to S3 and `data_bucket` and `dataset_directory` have been set to the location of your data.\n",
    "> - [ ] Dataset feature and target columns have been enumerated in `/code/HPODataset.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:25pt\"> **Rapids References** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [cloud-ml-examples](http://github.com/rapidsai/cloud-ml-examples)\n",
    "\n",
    "> [RAPIDS HPO](https://rapids.ai/hpo)\n",
    "\n",
    "> [cuML Documentation](https://docs.rapids.ai/api/cuml/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#8735fb; font-size:25pt\"> **SageMaker References** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [SageMaker Training Toolkit](https://github.com/aws/sagemaker-training-toolkit)\n",
    "\n",
    "> [Estimator Parameters](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)\n",
    "\n",
    "> Spot Instances [docs](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html), and [blog]()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
